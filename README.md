# ğŸ¥ Language Transcription Backend

Backend server for the Multi-User Live Video/Audio Translation System with real-time speech translation, user authentication, and room management.

## ğŸš€ Features

- **ğŸ¤ Real-time Speech Translation**: Live audio processing with instant translation
- **ğŸ‘¥ Multi-User Room Management**: Secure rooms with password protection
- **ğŸ” User Authentication**: Name-based user identification
- **ğŸŒ Multi-Language Support**: Tamil, Hindi, Spanish, French, and 10+ languages
- **ğŸ”Š WebSocket Communication**: Real-time audio broadcasting
- **ğŸ›¡ï¸ Security**: Password validation and access control
- **ğŸ¤– AI/ML Pipeline**: STT â†’ Translation â†’ TTS

## ğŸ› ï¸ Technology Stack

- **Node.js** with Express.js
- **WebSocket** for real-time communication
- **Python** for AI processing (STT, Translation, TTS)
- **Multer** for file uploads
- **Speech Recognition** (Google Speech API + offline fallback)
- **Language Translation** (Custom translation engine)
- **Text-to-Speech** (pyttsx3 for cross-platform TTS)

## ğŸ“‹ Prerequisites

- **Node.js** (v14 or higher)
- **Python** (v3.10 or higher)
- **npm** or **yarn**

## ğŸš€ Installation

### 1. Clone the repository
```bash
git clone https://github.com/Suganthi528/language-transcription-backend.git
cd language-transcription-backend
```

### 2. Install Node.js Dependencies
```bash
npm install
```

### 3. Install Python Dependencies
```bash
python -m pip install -r requirements.txt
```

## ğŸƒâ€â™‚ï¸ Running the Server

```bash
npm start
```

Server will run on `http://localhost:5000`

## ğŸ”„ API Endpoints

### Room Management
- `POST /create-room` - Create a new room with optional password
- `GET /rooms` - List all active rooms
- `WebSocket /` - Real-time communication

### Translation Pipeline
- `POST /translate-speech` - Complete speech translation pipeline
- `POST /live-translate` - Live video/audio translation
- `POST /stt` - Speech-to-text only
- `POST /translate` - Text translation only
- `POST /tts` - Text-to-speech only
- `GET /audio` - Get generated audio file

## ğŸŒ Supported Languages

- **Tamil (à®¤à®®à®¿à®´à¯)** - Primary focus
- **Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)**
- **Telugu (à°¤à±†à°²à±à°—à±)**
- **Kannada (à²•à²¨à³à²¨à²¡)**
- **Malayalam (à´®à´²à´¯à´¾à´³à´‚)**
- **Spanish, French, German, Italian**
- **Portuguese, Russian, Japanese, Korean, Chinese**

## ğŸ” WebSocket Events

### Client to Server
```javascript
// Join a room
{
  type: 'join-room',
  roomId: 'room123',
  userId: 'user456',
  userName: 'Alice',
  password: 'secret123',
  language: 'ta'
}

// Send audio chunk
{
  type: 'audio-chunk',
  audioData: 'base64_audio_data',
  targetLang: 'ta',
  roomId: 'room123'
}

// Leave room
{
  type: 'leave-room'
}
```

### Server to Client
```javascript
// Room joined successfully
{
  type: 'room-joined',
  roomId: 'room123',
  userId: 'user456',
  userName: 'Alice',
  connectedUsers: [...]
}

// Translation result
{
  type: 'translated-audio',
  audioUrl: '/static/audio_123.wav',
  originalText: 'Hello',
  translatedText: 'à®µà®£à®•à¯à®•à®®à¯',
  fromUserName: 'Alice'
}

// Error handling
{
  type: 'join-error',
  message: 'Invalid room password'
}
```

## ğŸ“ Project Structure

```
language-transcription-backend/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ synthesize.py              # Text-to-Speech with multi-language support
â”‚   â”œâ”€â”€ transcribe.py              # Speech-to-Text with Google API + offline fallback
â”‚   â”œâ”€â”€ transcribe_offline.py     # Offline transcription fallback
â”‚   â””â”€â”€ translate.py               # Language translation engine
â”œâ”€â”€ server.js                      # Main Express server with WebSocket support
â”œâ”€â”€ package.json                   # Node.js dependencies
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ test files/                    # Test suite
    â”œâ”€â”€ debug_audio.py
    â”œâ”€â”€ final_test.py
    â”œâ”€â”€ system_status.py
    â”œâ”€â”€ test_live_endpoint.py
    â”œâ”€â”€ test_multiuser.py
    â”œâ”€â”€ test_name_password.py
    â”œâ”€â”€ test_pipeline.py
    â””â”€â”€ test_system.py
```

## ğŸ§ª Testing

### Run All Tests
```bash
python final_test.py
```

### Test Individual Components
```bash
# Test translation
python python/translate.py "Hello world" ta

# Test TTS
python python/synthesize.py "à®µà®£à®•à¯à®•à®®à¯" ta test.wav

# Test room system
python test_name_password.py

# Test multi-user functionality
python test_multiuser.py
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Optional: Set custom port
PORT=5000

# Optional: Set Python path
PYTHON_PATH=/usr/bin/python3
```

### Dependencies

#### Node.js Dependencies
- express: Web framework
- ws: WebSocket library
- cors: Cross-origin resource sharing
- multer: File upload handling

#### Python Dependencies
- googletrans: Translation service
- pyttsx3: Text-to-speech
- SpeechRecognition: Speech-to-text
- numpy: Numerical computing
- requests: HTTP library
- pydub: Audio processing

## ğŸš¨ Troubleshooting

### Common Issues

**"Module not found" errors**
```bash
npm install
python -m pip install -r requirements.txt
```

**"Port already in use"**
```bash
# Kill process on port 5000
npx kill-port 5000
```

**"Python command not found"**
```bash
# Use python3 instead of python
python3 -m pip install -r requirements.txt
```

**Translation not working**
- Check internet connection for Google Translate API
- Verify Python dependencies are installed
- Try offline fallback mode

## ğŸ”„ API Usage Examples

### Create a Room
```javascript
fetch('http://localhost:5000/create-room', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    roomName: 'MeetingRoom',
    password: 'secret123',
    creatorName: 'Alice'
  })
})
```

### Translate Text
```javascript
fetch('http://localhost:5000/translate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Hello world',
    targetLang: 'ta'
  })
})
```

### Upload Audio for Translation
```javascript
const formData = new FormData();
formData.append('audio', audioBlob);
formData.append('targetLang', 'ta');

fetch('http://localhost:5000/live-translate', {
  method: 'POST',
  body: formData
})
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

- **Suganthi528** - *Initial work* - [Suganthi528](https://github.com/Suganthi528)

## ğŸ™ Acknowledgments

- Google Speech Recognition API
- Node.js and Express.js communities
- Python TTS libraries
- WebSocket technology

---

**ğŸŠ Ready to power real-time translation applications! ğŸŒ**